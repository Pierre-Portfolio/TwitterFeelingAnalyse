{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "466a02c1",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "tagger = UnigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e200e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_neg=r'D:\\OneDrive - De Vinci\\ESILV\\A5\\Machine_learning_NLP\\wp2\\txt_sentoken\\neg'\n",
    "path_pos=r'D:\\OneDrive - De Vinci\\ESILV\\A5\\Machine_learning_NLP\\wp2\\txt_sentoken\\pos'\n",
    "\n",
    "path=r'twitter_data_161122.csv'\n",
    "\n",
    "pos_reviews =os.listdir(path_pos)\n",
    "neg_reviews =os.listdir(path_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77498774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path,sep=',',encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0906ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=df.loc[0]['Text']\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa43a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predire(text):\n",
    "    '''\n",
    "    if type=='adverbe':\n",
    "        Ltag=['RB','RBR','RBS','RBW']\n",
    "        senti='r'\n",
    "    elif type=='verbe':\n",
    "        Ltag=['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "        senti='v'\n",
    "    '''\n",
    "\n",
    "\n",
    "    texte=word_tokenize(text)\n",
    "    L=set()\n",
    "    tag=tagger.tag(texte)\n",
    "\n",
    "    for t in tag:\n",
    "        L.add(t[0])\n",
    "        #print(t[0])\n",
    "\n",
    "    pos_score=0\n",
    "    neg_score=0\n",
    "\n",
    "    for adv in L:\n",
    "        adv_senti = list(swn.senti_synsets(adv))\n",
    "        if len(adv_senti)!=0:\n",
    "            #print(adv_senti[0])\n",
    "            pos_score+=adv_senti[0].pos_score()\n",
    "            neg_score+=adv_senti[0].neg_score()\n",
    "\n",
    "\n",
    "    res=''\n",
    "    if pos_score > neg_score:\n",
    "        res='pos'\n",
    "    elif pos_score < neg_score:\n",
    "        res='neg'\n",
    "\n",
    "    return res,pos_score,neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predire(test,'adverbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('--------------')\n",
    "    print(df.loc[i]['Text'])\n",
    "    print(Predire(df.loc[i]['Text']))\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3494522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "neutre=0\n",
    "for index,row in df.iterrows():\n",
    "    if Predire(row['Text'])[0] == 'pos':\n",
    "        pos+=1\n",
    "    elif Predire(row['Text'])[0] == 'neg':\n",
    "        neg+=1\n",
    "    else:\n",
    "        neutre+=1\n",
    "\n",
    "print('total= ', len(df))\n",
    "print(pos,neg,neutre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a06c70",
   "metadata": {},
   "source": [
    "# XLNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "!pip install -q -U watermark\n",
    "!pip install SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch,transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03867720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import XLNetTokenizer, XLNetModel, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report#, accuracy\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from pylab import rcParams\n",
    "\n",
    "from torch import nn, optim\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,RandomSampler,SequentialSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9998266",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d964ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\owen9\\OneDrive\\Documents\\GitHub\\TwitterFeelingAnalyse\\Tests_modeles\\Train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb450ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67370e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text)\n",
    "    text = re.sub('\\t', ' ',  text)\n",
    "    text = re.sub(r\" +\", ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c48b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 8, 6\n",
    "sns.countplot(df['label'])\n",
    "plt.xlabel('review score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1cb2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e184a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, XLNetModel\n",
    "PRE_TRAINED_MODEL_NAME = 'xlnet-base-cased'\n",
    "tokenizer = XLNetTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04722ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = \"India is my country. All Indians are my brothers and sisters\"\n",
    "encodings = tokenizer.encode_plus(input_txt, add_special_tokens=True, max_length=16, return_tensors='pt', return_token_type_ids=False, return_attention_mask=True, pad_to_max_length=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd382b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
